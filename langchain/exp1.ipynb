{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "feca1f7d-2086-4b65-8a5f-5e4c7cb8e393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！我是你的智能助手，随时为你提供帮助。我的主要功能包括：\n",
      "\n",
      "1. **信息查询**：解答各类问题，提供知识和建议  \n",
      "2. **生活助手**：天气查询、翻译、计算等实用工具  \n",
      "3. **创意支持**：写作灵感、头脑风暴、内容优化  \n",
      "4. **学习辅导**：概念讲解、题目分析、语言学习  \n",
      "\n",
      "我没有实体形态，24小时在线，响应速度快，且会持续学习更新知识库。无论是工作、学习还是生活中的问题，都可以随时向我咨询。  \n",
      "\n",
      "我的目标是提供准确、友好、安全的帮助，但请注意我提供的信息仅供参考，重要决策建议多方核实。  \n",
      "\n",
      "有什么具体需要帮忙的吗？ 😊\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "DeepSeek_API_KEY = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "#print(DeepSeek_API_KEY)\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=DeepSeek_API_KEY, base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"你是乐于助人的助手，请根据用户的问题回答\"},\n",
    "        {\"role\": \"user\", \"content\": \"你好，请介绍一下你自己\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c03369b8-2ca7-4791-8b18-9a06fc6a775c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_deepseek.chat_models.ChatDeepSeek'>\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(model=\"deepseek-chat\", model_provider=\"deepseek\")\n",
    "print(type(model))\n",
    "question = \"你好，请介绍一下你自己\"\n",
    "#result = model.invoke(question)\n",
    "#print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5165a17d-b6f7-44ee-b161-ea24e4675ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-BuHahOBJQimyCNwes10f700b05Np2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='你好！我是一个由人工智能驱动的助手，旨在帮助回答问题、提供信息和解决问题。我接受了广泛的培训，可以处理各种主题和问题。如果你有任何疑问或者需要帮助，随时可以向我提问！', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1752753687, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_ee1d74bde0', usage=CompletionUsage(completion_tokens=55, prompt_tokens=29, total_tokens=84, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "# 使用公司自己部署的模型\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "Amap_API_KEY = os.getenv(\"AMAP_API_KEY\")\n",
    "#print(Amap_API_KEY)\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=Amap_API_KEY, base_url=\"https://pre-lmops.amap.com/open_api/v1\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt4o\",\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"你是乐于助人的助手，请根据用户的问题回答\"},\n",
    "        {\"role\": \"user\", \"content\": \"你好，请介绍一下你自己\"}\n",
    "    ]\n",
    ")\n",
    "#print(response.choices[0].message.content)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f271944-7d7a-434c-b981-68eab0d4b71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_deepseek.chat_models.ChatDeepSeek'>\n",
      "你好！我是 **DeepSeek Chat**，由深度求索（DeepSeek）公司开发的智能AI助手。我可以帮助你解答各种问题，包括学习、工作、编程、生活百科、创意写作等。以下是我的特点：\n",
      "\n",
      "### 🌟 **我的能力**\n",
      "- **知识丰富**：我的知识截至2024年7月，覆盖科技、历史、文学、数学、编程等多个领域。\n",
      "- **超长上下文**：支持**128K**上下文，能记住更长的对话内容，适合处理复杂问题。\n",
      "- **文件阅读**：可以解析 **PDF、Word、Excel、PPT、TXT** 等文件，帮助你提取关键信息。\n",
      "- **编程助手**：支持多种编程语言（Python、C++、Java等），能帮你调试代码、优化算法、解释错误。\n",
      "- **免费使用**：目前无需付费，你可以随时向我提问！\n",
      "\n",
      "### 🛠 **我能帮你做什么？**\n",
      "- **学习辅导**：解答数学题、讲解概念、提供论文思路。\n",
      "- **工作助手**：写邮件、做PPT、分析数据、优化简历。\n",
      "- **创意写作**：生成故事、诗歌、广告文案，甚至帮你起名字！\n",
      "- **生活建议**：旅行规划、健康小贴士、美食推荐。\n",
      "- **技术支持**：代码调试、算法优化、技术文档解读。\n",
      "\n",
      "### 📂 **文件处理**\n",
      "你可以上传文档，我会帮你总结、提取关键信息，甚至回答相关问题！\n",
      "\n",
      "### 💬 **随时交流**\n",
      "无论是简单的问题，还是复杂的任务，我都会尽力帮你。你可以随时向我提问，我会用最清晰、详细的方式回答你！😊\n",
      "\n",
      "有什么我可以帮你的吗？\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(model=\"deepseek-chat\", model_provider=\"deepseek\")\n",
    "#print(type(model))\n",
    "question = \"你好，请介绍一下你自己\"\n",
    "result = model.invoke(question)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76ee3e54-bd73-41f5-a1c6-3c7ffef5a95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好！我是 **DeepSeek Chat**，由深度求索（DeepSeek）公司研发的智能 AI 助手。我可以帮助你解答各种问题，包括学习、工作、编程、写作、生活建议等。以下是我的一些特点：  \\n\\n✨ **免费使用**：目前无需付费，你可以随时向我提问。  \\n📚 **知识丰富**：我的知识截止到 **2024 年 7 月**，可以为你提供最新的信息（但无法实时更新）。  \\n📝 **多文档处理**：支持上传 **txt、pdf、ppt、word、excel** 等文件，并能从中提取和总结信息。  \\n💡 **超长上下文**：支持 **128K** 上下文，能记住更长的对话内容，适合处理复杂问题。  \\n🚀 **高效智能**：无论是写作、翻译、代码编写，还是逻辑推理、数学计算，我都能帮上忙！  \\n\\n你可以问我任何问题，比如：  \\n- **学习**：如何高效复习？某个数学题怎么解？  \\n- **工作**：如何写商业计划书？简历如何优化？  \\n- **编程**：Python/Java/C++ 代码调试、算法思路等。  \\n- **生活**：旅行推荐、美食建议、心理疏导等。  \\n\\n随时向我提问吧，我会尽力帮助你！😊'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(model=\"deepseek-chat\", model_provider=\"deepseek\")\n",
    "question = \"你好，请介绍一下你自己\"\n",
    "basic_qa_chain = model | StrOutputParser()\n",
    "basic_qa_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3890d2b5-b0ee-4012-b81d-578e2e26b278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Prompt模板\n",
    "from langchain.output_parsers.boolean import BooleanOutputParser\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(model=\"deepseek-chat\", model_provider=\"deepseek\")\n",
    "prompt_template = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"你是一个助人为乐的助手，请根据用户的问题给出回答\"),\n",
    "        (\"user\", \"这是用户的问题：{topic}, 请用yes或no来回答\")\n",
    "    ]\n",
    ")\n",
    "bool_qa_chain = prompt_template | model | BooleanOutputParser()\n",
    "#question = \"1+1是否大于2\"\n",
    "question = \"1+1是否等于2\"\n",
    "result = bool_qa_chain.invoke(question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e153f97d-67ac-434c-88a2-d4ebdb3651c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"name\": string  // 用户的姓名\n",
      "\t\"age\": string  // 用户的年龄\n",
      "}\n",
      "```\n",
      "{'name': '李雷', 'age': '25'}\n"
     ]
    }
   ],
   "source": [
    "# 格式化输出\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "schemas = [\n",
    "    ResponseSchema(name=\"name\", description=\"用户的姓名\"),\n",
    "    ResponseSchema(name=\"age\", description=\"用户的年龄\")\n",
    "]\n",
    "parser = StructuredOutputParser.from_response_schemas(schemas)\n",
    "\n",
    "# parser.get_format_instructions()返回一个字符串，给LLM一些指令\n",
    "print(parser.get_format_instructions())\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"请根据以下内容提取用户信息，并返回json格式：\\n{input}\\n\\n{format_instructions}\"\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "result = chain.invoke({\"input\":\"用户叫李雷，今年25岁，是一名工程师。\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15dc457c-affe-41b3-8a4c-e716fec82373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中间结果: content='苹果公司在加州总部发布全新AI芯片M4，性能较前代提升50%，专为下一代MacBook Pro及iPad Pro设计。该芯片采用3nm制程工艺，内置更强神经网络引擎，可高效处理机器学习任务。苹果称M4将显著提升设备在图像生成、实时语音识别等AI应用中的表现，预计首批搭载产品将于2024年底上市。此举被视为苹果加码AI领域、与英伟达等竞争对手抗衡的重要举措。（98字）' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 101, 'prompt_tokens': 28, 'total_tokens': 129, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 28}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0623_fp8_kvcache', 'id': '36d5abd7-69e8-4459-a7f0-d6c44dffc6a4', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--381f3bd8-90b5-4c01-9c46-cfbab0a97dd4-0' usage_metadata={'input_tokens': 28, 'output_tokens': 101, 'total_tokens': 129, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n",
      "{'time': '2024年底', 'location': '加州总部', 'event': '苹果公司发布全新AI芯片M4，性能较前代提升50%，专为下一代MacBook Pro及iPad Pro设计。该芯片采用3nm制程工艺，内置更强神经网络引擎，可高效处理机器学习任务。苹果称M4将显著提升设备在图像生成、实时语音识别等AI应用中的表现。此举被视为苹果加码AI领域、与英伟达等竞争对手抗衡的重要举措。'}\n"
     ]
    }
   ],
   "source": [
    "# 复合链\n",
    "import os\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables.base import RunnableLambda\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "DeepSeek_API_KEY = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "model = init_chat_model(model=\"deepseek-chat\", model_provider=\"deepseek\")\n",
    "news_gen_prompt = PromptTemplate.from_template(\n",
    "    \"请根据以下新闻标题写一段简短的新闻内容（100字以内）：\\n\\n标题：{title}\"\n",
    ")\n",
    "\n",
    "def debug_print(x):\n",
    "    print(\"中间结果:\", x)\n",
    "    return x\n",
    "\n",
    "news_chain = news_gen_prompt | model\n",
    "\n",
    "schemas = [\n",
    "    ResponseSchema(name=\"time\", description=\"事件发生的时间\"),\n",
    "    ResponseSchema(name=\"location\", description=\"事件发生的地点\"),\n",
    "    ResponseSchema(name=\"event\", description=\"发生的具体事件\")\n",
    "]\n",
    "\n",
    "parser = StructuredOutputParser.from_response_schemas(schemas)\n",
    "\n",
    "summary_prompt = PromptTemplate.from_template(\n",
    "    \"请从新闻内容中提取关键信息，并返回结构化json格式：\\n\\n{news}\\n\\n{format_instructions}\"\n",
    ")\n",
    "\n",
    "summary_chain = (\n",
    "    summary_prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "# 可以自定义的一些函数，作为chain的一部分\n",
    "debug_node = RunnableLambda(debug_print)\n",
    "\n",
    "full_chain = news_chain | debug_node | summary_chain\n",
    "result = full_chain.invoke({\"title\":\"苹果公司在加州发布新款AI芯片\"})\n",
    "print(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef8c797d-360b-4abb-8c45-037fee13426b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_0_40808bc6-629b-4131-a510-9d6fd75ff4a5', 'function': {'arguments': '{\"a\":3,\"b\":12}', 'name': 'multiply'}, 'type': 'function', 'index': 0}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 246, 'total_tokens': 268, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 246}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0623_fp8_kvcache', 'id': '829797af-163b-462d-8450-18d19aacb1ad', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None} id='run--26945782-eea6-4c91-ab0f-7263c4d84188-0' tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_0_40808bc6-629b-4131-a510-9d6fd75ff4a5', 'type': 'tool_call'}] usage_metadata={'input_tokens': 246, 'output_tokens': 22, 'total_tokens': 268, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "load_dotenv(override=True)\n",
    "DeepSeek_API_KEY = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "model = init_chat_model(model=\"deepseek-chat\", model_provider=\"deepseek\")\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers.\n",
    "\n",
    "    Args:\n",
    "        a: First integer\n",
    "        b: Second integer\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers.\n",
    "\n",
    "    Args:\n",
    "        a: First integer\n",
    "        b: Second integer\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "tools = [add, multiply]\n",
    "\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "query = \"What is 3 * 12?\"\n",
    "\n",
    "result = model_with_tools.invoke(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05919987-5a8d-4f24-8f2d-697dbf7ac2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
